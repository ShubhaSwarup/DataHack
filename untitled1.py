# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w4p1wNhBySL7rZ1ao3KRa4M4FgmnLf4w
"""

import pandas as pd

# Load the datasets
train_features = pd.read_csv('training_set_features.csv')
test_features = pd.read_csv('test_set_features.csv')
train_labels = pd.read_csv('training_set_labels.csv')

# Ensure that respondent_id is the index to maintain consistency
train_features.set_index('respondent_id', inplace=True)
test_features.set_index('respondent_id', inplace=True)
train_labels.set_index('respondent_id', inplace=True)

# Check the indices and shapes
print(train_features.index.equals(train_labels.index))  # Should be True
print(train_features.shape, test_features.shape, train_labels.shape)

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# Define categorical and numerical columns
categorical_cols = [
    'age_group', 'education', 'race', 'sex', 'income_poverty', 'marital_status',
    'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa',
    'employment_industry', 'employment_occupation'
]

numerical_cols = [
    'xyz_concern', 'xyz_knowledge', 'behavioral_antiviral_meds', 'behavioral_avoidance',
    'behavioral_face_mask', 'behavioral_wash_hands', 'behavioral_large_gatherings',
    'behavioral_outside_home', 'behavioral_touch_face', 'doctor_recc_xyz',
    'doctor_recc_seasonal', 'chronic_med_condition', 'child_under_6_months',
    'health_worker', 'health_insurance', 'opinion_xyz_vacc_effective', 'opinion_xyz_risk',
    'opinion_xyz_sick_from_vacc', 'opinion_seas_vacc_effective', 'opinion_seas_risk',
    'opinion_seas_sick_from_vacc', 'household_adults', 'household_children'
]

# Preprocessing pipelines for numerical and categorical features
numerical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean for numerical features
    ('scaler', StandardScaler())  # Standardize numerical features
])

categorical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with the most frequent value for categorical features
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))  # One-hot encode categorical features
])

# Combine preprocessing steps
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_pipeline, numerical_cols),
        ('cat', categorical_pipeline, categorical_cols)
    ],
    remainder='passthrough'  # Ensure that no columns are dropped
)

# Separate features and target variables for training set
X_train = train_features
y_train = train_labels
X_test = test_features

# Preprocess the training and testing data
X_train_preprocessed = preprocessor.fit_transform(X_train)
X_test_preprocessed = preprocessor.transform(X_test)

# Ensure that no samples are dropped
print(X_train_preprocessed.shape, X_test_preprocessed.shape)
print(y_train.shape)

from sklearn.multioutput import MultiOutputClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import numpy as np

# Ensure consistent shapes before splitting
print(X_train_preprocessed.shape, y_train.shape)

# Split the training data into training and validation sets
X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_preprocessed, y_train, test_size=0.2, random_state=42)

# Ensure consistent shapes after split
print(X_train_split.shape, X_val_split.shape, y_train_split.shape, y_val_split.shape)

# Initialize the base model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Wrap the model with MultiOutputClassifier
multi_target_model = MultiOutputClassifier(rf_model, n_jobs=-1)

# Train the model
multi_target_model.fit(X_train_split, y_train_split)

# Make predictions
y_val_pred_proba = multi_target_model.predict_proba(X_val_split)

# Convert the list of arrays into a 2D array
y_val_pred_proba = np.array(y_val_pred_proba)[:, :, 1].T

# Evaluate the model using ROC AUC score
roc_auc_xyz = roc_auc_score(y_val_split['xyz_vaccine'], y_val_pred_proba[:, 0])
roc_auc_seasonal = roc_auc_score(y_val_split['seasonal_vaccine'], y_val_pred_proba[:, 1])
mean_roc_auc = (roc_auc_xyz + roc_auc_seasonal) / 2

print(f'ROC AUC for XYZ Vaccine: {roc_auc_xyz}')
print(f'ROC AUC for Seasonal Vaccine: {roc_auc_seasonal}')
print(f'Mean ROC AUC: {mean_roc_auc}')

from sklearn.multioutput import MultiOutputClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score
import numpy as np

# Initialize the base model with limited n_jobs
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=2)

# Wrap the model with MultiOutputClassifier
multi_target_model = MultiOutputClassifier(rf_model, n_jobs=2)

# Define the parameter grid
param_grid = {
    'estimator__n_estimators': [50, 100],
    'estimator__max_depth': [None, 10],
    'estimator__min_samples_split': [2, 5],
    'estimator__min_samples_leaf': [1, 2]
}

# Initialize GridSearchCV with limited n_jobs
grid_search = GridSearchCV(multi_target_model, param_grid, cv=3, scoring='roc_auc', n_jobs=2)

# Fit GridSearchCV
grid_search.fit(X_train_split, y_train_split)

# Get the best parameters and the best score
best_params = grid_search.best_params_
best_score = grid_search.best_score_

print(f'Best parameters: {best_params}')
print(f'Best ROC AUC score from GridSearchCV: {best_score}')

# Make predictions with the best model
best_model = grid_search.best_estimator_
y_test_pred_proba = best_model.predict_proba(X_test_preprocessed)

# Convert the list of arrays into a 2D array
y_test_pred_proba = np.array(y_test_pred_proba)[:, :, 1].T

# Prepare the submission file
submission = pd.DataFrame({
    'respondent_id': test_features.index,
    'xyz_vaccine': y_test_pred_proba[:, 0],
    'seasonal_vaccine': y_test_pred_proba[:, 1]
})

submission.to_csv('submission.csv', index=False)
print(submission.head())

